{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prottushee/IDS_CICIoT2023/blob/main/MeanTeacher(CICIot2023).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJLnYPk8HQu_"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sSV594bbbHdy",
        "outputId": "2c3ecfd5-f61b-4e12-e17e-499fc0756284"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AGvnytDuHXUf",
        "outputId": "6e03f905-10b8-4ba2-c29a-a4f11d773999"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.1)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorflow-io-gcs-filesystem, tensorboard-data-server, google-pasta, tensorboard, astunparse, tensorflow\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 google-pasta-0.2.0 libclang-18.1.1 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 werkzeug-3.1.3 wheel-0.45.1\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAwT3OWpxZEd",
        "outputId": "918a5534-1185-4f72-d410-d5a0420d9397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Train: (2839961, 32), Val: (709991, 32)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load saved SMOTE-balanced labeled dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/CICIoT2023_Clients/labeled_balanced_20percent.csv\")\n",
        "\n",
        "# Re-encode labels (ensures consistency)\n",
        "le = LabelEncoder()\n",
        "df['label'] = le.fit_transform(df['label'])\n",
        "\n",
        "# Feature-label split\n",
        "X = df.drop(columns=['label'])\n",
        "y = df['label']\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Recalculate class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
        "class_weight_dict = dict(zip(np.unique(y), class_weights))\n",
        "\n",
        "# Train-Test split (80/20)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "print(f\"‚úÖ Train: {X_train.shape}, Val: {X_val.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gwLN2zPjBk3",
        "outputId": "1f5f318c-8ba8-429f-e8f8-92ddcf50878e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 2 Complete [01h 08m 12s]\n",
            "val_accuracy: 0.8509164452552795\n",
            "\n",
            "Best val_accuracy So Far: 0.8509164452552795\n",
            "Total elapsed time: 01h 34m 18s\n",
            "\n",
            "Search: Running Trial #3\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "3                 |3                 |num_layers\n",
            "320               |320               |units_0\n",
            "0.2               |0.3               |dropout_0\n",
            "384               |384               |units_1\n",
            "0.5               |0.1               |dropout_1\n",
            "0.00025612        |0.004759          |lr\n",
            "512               |64                |units_2\n",
            "0.4               |0.1               |dropout_2\n",
            "\n",
            "Epoch 1/30\n",
            "22188/22188 - 485s - 22ms/step - accuracy: 0.6847 - loss: 0.8349 - val_accuracy: 0.7902 - val_loss: 0.5183\n",
            "Epoch 2/30\n",
            "22188/22188 - 481s - 22ms/step - accuracy: 0.7677 - loss: 0.5849 - val_accuracy: 0.8027 - val_loss: 0.4671\n",
            "Epoch 3/30\n",
            "22188/22188 - 483s - 22ms/step - accuracy: 0.7838 - loss: 0.5326 - val_accuracy: 0.8097 - val_loss: 0.4508\n",
            "Epoch 4/30\n",
            "22188/22188 - 481s - 22ms/step - accuracy: 0.7913 - loss: 0.5085 - val_accuracy: 0.7904 - val_loss: 0.5071\n",
            "Epoch 5/30\n",
            "22188/22188 - 482s - 22ms/step - accuracy: 0.7964 - loss: 0.4925 - val_accuracy: 0.8042 - val_loss: 0.4602\n",
            "Epoch 6/30\n",
            "22188/22188 - 482s - 22ms/step - accuracy: 0.7992 - loss: 0.4830 - val_accuracy: 0.8260 - val_loss: 0.4144\n",
            "Epoch 7/30\n",
            "22188/22188 - 482s - 22ms/step - accuracy: 0.8021 - loss: 0.4742 - val_accuracy: 0.8256 - val_loss: 0.4090\n",
            "Epoch 8/30\n",
            "22188/22188 - 482s - 22ms/step - accuracy: 0.8044 - loss: 0.4674 - val_accuracy: 0.8284 - val_loss: 0.4000\n",
            "Epoch 9/30\n",
            "22188/22188 - 481s - 22ms/step - accuracy: 0.8065 - loss: 0.4616 - val_accuracy: 0.8290 - val_loss: 0.3988\n",
            "Epoch 10/30\n",
            "22188/22188 - 482s - 22ms/step - accuracy: 0.8075 - loss: 0.4573 - val_accuracy: 0.8308 - val_loss: 0.3946\n",
            "Epoch 11/30\n",
            "22188/22188 - 481s - 22ms/step - accuracy: 0.8091 - loss: 0.4533 - val_accuracy: 0.8328 - val_loss: 0.3895\n",
            "Epoch 12/30\n",
            "22188/22188 - 482s - 22ms/step - accuracy: 0.8103 - loss: 0.4499 - val_accuracy: 0.8034 - val_loss: 0.4692\n",
            "Epoch 13/30\n",
            "22188/22188 - 482s - 22ms/step - accuracy: 0.8113 - loss: 0.4463 - val_accuracy: 0.8327 - val_loss: 0.3862\n",
            "Epoch 14/30\n",
            "22188/22188 - 481s - 22ms/step - accuracy: 0.8122 - loss: 0.4428 - val_accuracy: 0.8366 - val_loss: 0.3823\n",
            "Epoch 15/30\n",
            "22188/22188 - 481s - 22ms/step - accuracy: 0.8132 - loss: 0.4409 - val_accuracy: 0.8370 - val_loss: 0.3874\n",
            "Epoch 16/30\n",
            "22188/22188 - 481s - 22ms/step - accuracy: 0.8141 - loss: 0.4384 - val_accuracy: 0.8375 - val_loss: 0.3822\n",
            "Epoch 17/30\n",
            "22188/22188 - 481s - 22ms/step - accuracy: 0.8148 - loss: 0.4361 - val_accuracy: 0.8353 - val_loss: 0.3807\n",
            "Epoch 18/30\n",
            "22188/22188 - 481s - 22ms/step - accuracy: 0.8153 - loss: 0.4345 - val_accuracy: 0.8383 - val_loss: 0.3760\n",
            "Epoch 19/30\n",
            "22188/22188 - 481s - 22ms/step - accuracy: 0.8159 - loss: 0.4327 - val_accuracy: 0.8374 - val_loss: 0.3801\n",
            "Epoch 20/30\n",
            "22188/22188 - 481s - 22ms/step - accuracy: 0.8164 - loss: 0.4309 - val_accuracy: 0.8390 - val_loss: 0.3885\n",
            "Epoch 21/30\n"
          ]
        }
      ],
      "source": [
        "# ======================== Install keras-tuner if not installed ========================\n",
        "!pip install keras-tuner --quiet\n",
        "\n",
        "# ======================== Import libraries ========================\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras_tuner import RandomSearch\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "# ======================== Assume your preprocessed data is ready ========================\n",
        "# X_train, y_train, X_val, y_val, class_weight_dict, le (LabelEncoder for decoding labels)\n",
        "# num_classes should be:\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "# ======================== Build model function for tuner ========================\n",
        "def build_model(hp):\n",
        "    inputs = keras.Input(shape=(X_train.shape[1],))\n",
        "    x = inputs\n",
        "\n",
        "    # Hyperparameter: number of layers\n",
        "    for i in range(hp.Int(\"num_layers\", 2, 4)):\n",
        "        units = hp.Int(f\"units_{i}\", min_value=64, max_value=512, step=64)\n",
        "        x = keras.layers.Dense(units, activation=\"relu\")(x)\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "        dropout_rate = hp.Float(f\"dropout_{i}\", min_value=0.1, max_value=0.5, step=0.1)\n",
        "        x = keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    outputs = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "\n",
        "    # Hyperparameter: learning rate (Adam only)\n",
        "    lr = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=SparseCategoricalCrossentropy(),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# ======================== Set tuner ========================\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=20,  # You can increase this later\n",
        "    executions_per_trial=1,\n",
        "    directory=\"dnn_tuning\",\n",
        "    project_name=\"ciciot2023_tuning_adam_only\"\n",
        ")\n",
        "\n",
        "# ======================== Run hyperparameter search ========================\n",
        "tuner.search(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=[keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)],\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# ======================== Get the best model ========================\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_loss, val_acc = best_model.evaluate(X_val, y_val)\n",
        "print(f\"\\n‚úÖ Best model validation accuracy: {val_acc * 100:.2f}%\")\n",
        "\n",
        "# ======================== Evaluation block ========================\n",
        "\n",
        "# Make predictions\n",
        "y_pred_prob = best_model.predict(X_val, batch_size=512)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "# Accuracy\n",
        "acc = accuracy_score(y_val, y_pred)\n",
        "print(f\"\\n‚úÖ Hyperparameter Tuned DNN Accuracy: {acc * 100:.2f}%\")\n",
        "\n",
        "# Classification report with proper label decoding\n",
        "present_labels = np.unique(y_val)\n",
        "present_class_names = [str(cls_name) for cls_name in le.inverse_transform(present_labels)]\n",
        "\n",
        "print(\"\\nüìä Classification Report:\")\n",
        "print(classification_report(y_val, y_pred, labels=present_labels, target_names=present_class_names))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cVbtrRXTYeR"
      },
      "source": [
        "#Baseline DNN with 100% labeled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "collapsed": true,
        "id": "unOPv2Klxzf-",
        "outputId": "77bcea44-9bdb-4425-85b3-01937d6f01a7"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1490889066>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparseCategoricalCrossentropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "# Build the DNN\n",
        "def build_dnn(input_dim, num_classes):\n",
        "    inputs = Input(shape=(input_dim,))\n",
        "    x = Dense(512, activation='relu')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "# Compile model\n",
        "num_classes = len(np.unique(y))\n",
        "dnn_model = build_dnn(X_train.shape[1], num_classes)\n",
        "dnn_model.compile(\n",
        "   optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9),\n",
        "    loss=SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train\n",
        "history = dnn_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=10,\n",
        "    batch_size=512,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UEhUrP7supIR",
        "outputId": "32ced7bf-a05a-4d1e-93ee-2be79d32ec05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1387/1387\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step\n",
            "\n",
            "‚úÖ Supervised DNN Accuracy: 83.10%\n",
            "\n",
            "üìä Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98     22187\n",
            "           1       0.57      0.64      0.60     22187\n",
            "           2       0.91      1.00      0.95     22187\n",
            "           3       0.94      0.99      0.96     22187\n",
            "           4       0.99      1.00      0.99     22187\n",
            "           5       0.93      0.89      0.91     22187\n",
            "           6       1.00      1.00      1.00     22188\n",
            "           7       0.99      1.00      0.99     22188\n",
            "           8       1.00      1.00      1.00     22187\n",
            "           9       1.00      1.00      1.00     22187\n",
            "          10       0.48      0.20      0.29     22188\n",
            "          11       0.42      0.73      0.53     22187\n",
            "          12       0.57      0.79      0.66     22187\n",
            "          13       0.99      1.00      0.99     22187\n",
            "          14       0.77      0.70      0.73     22188\n",
            "          15       0.90      0.99      0.94     22187\n",
            "          16       0.89      0.93      0.91     22187\n",
            "          17       0.54      0.45      0.49     22187\n",
            "          18       0.66      0.41      0.51     22187\n",
            "          19       1.00      1.00      1.00     22188\n",
            "          20       0.78      0.62      0.69     22188\n",
            "          21       0.99      0.99      0.99     22187\n",
            "          22       0.99      0.98      0.99     22187\n",
            "          23       1.00      1.00      1.00     22187\n",
            "          24       0.75      0.83      0.79     22187\n",
            "          25       0.60      0.26      0.36     22187\n",
            "          26       0.95      1.00      0.97     22187\n",
            "          27       0.56      0.65      0.60     22187\n",
            "          28       0.94      1.00      0.97     22188\n",
            "          29       0.99      0.98      0.99     22187\n",
            "          30       0.61      0.61      0.61     22187\n",
            "          31       0.92      0.99      0.95     22187\n",
            "\n",
            "    accuracy                           0.83    709991\n",
            "   macro avg       0.83      0.83      0.82    709991\n",
            "weighted avg       0.83      0.83      0.82    709991\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ========================== Evaluation Block  of baseline DNN training with 100% label & rmsprop optimizer ==========================\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Make predictions\n",
        "batch_size = 512 # Define batch_size\n",
        "y_pred_prob = dnn_model.predict(X_val, batch_size=batch_size)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "acc = accuracy_score(y_val, y_pred)\n",
        "print(f\"\\n‚úÖ Supervised DNN Accuracy: {acc * 100:.2f}%\")\n",
        "\n",
        "# Handle label decoding properly\n",
        "present_labels = np.unique(y_val)\n",
        "present_class_names = [str(cls_name) for cls_name in le.inverse_transform(present_labels)]\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nüìä Classification Report:\")\n",
        "print(classification_report(y_val, y_pred, labels=present_labels, target_names=present_class_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4gUmHod2_zr"
      },
      "source": [
        "#Baseline DNN with 20% labeled datas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xGtxNZP3lpFI",
        "outputId": "8e5c8a33-d0d1-4b4d-f9b4-be0cde658ad9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Baseline DNN with Adam\n",
            "Epoch 1/10\n",
            "1110/1110 - 56s - 50ms/step - accuracy: 0.6264 - loss: 1.0072 - val_accuracy: 0.7081 - val_loss: 0.7285\n",
            "Epoch 2/10\n",
            "1110/1110 - 53s - 48ms/step - accuracy: 0.7091 - loss: 0.7408 - val_accuracy: 0.7645 - val_loss: 0.5977\n",
            "Epoch 3/10\n",
            "1110/1110 - 53s - 47ms/step - accuracy: 0.7410 - loss: 0.6562 - val_accuracy: 0.7791 - val_loss: 0.5459\n",
            "Epoch 4/10\n",
            "1110/1110 - 53s - 47ms/step - accuracy: 0.7582 - loss: 0.6098 - val_accuracy: 0.7818 - val_loss: 0.5581\n",
            "Epoch 5/10\n",
            "1110/1110 - 53s - 47ms/step - accuracy: 0.7714 - loss: 0.5739 - val_accuracy: 0.7951 - val_loss: 0.4991\n",
            "Epoch 6/10\n",
            "1110/1110 - 53s - 47ms/step - accuracy: 0.7779 - loss: 0.5541 - val_accuracy: 0.8018 - val_loss: 0.4770\n",
            "Epoch 7/10\n",
            "1110/1110 - 52s - 47ms/step - accuracy: 0.7810 - loss: 0.5424 - val_accuracy: 0.7863 - val_loss: 0.4973\n",
            "Epoch 8/10\n",
            "1110/1110 - 53s - 47ms/step - accuracy: 0.7842 - loss: 0.5300 - val_accuracy: 0.8075 - val_loss: 0.4586\n",
            "Epoch 9/10\n",
            "1110/1110 - 53s - 47ms/step - accuracy: 0.7873 - loss: 0.5222 - val_accuracy: 0.8027 - val_loss: 0.4722\n",
            "Epoch 10/10\n",
            "1110/1110 - 53s - 47ms/step - accuracy: 0.7909 - loss: 0.5116 - val_accuracy: 0.8048 - val_loss: 0.4677\n",
            "\u001b[1m1387/1387\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step\n",
            "\n",
            "Training Baseline DNN with RMSprop\n",
            "Epoch 1/10\n",
            "1110/1110 - 54s - 49ms/step - accuracy: 0.6355 - loss: 0.9745 - val_accuracy: 0.7170 - val_loss: 0.7122\n",
            "Epoch 2/10\n",
            "1110/1110 - 52s - 47ms/step - accuracy: 0.7114 - loss: 0.7336 - val_accuracy: 0.7420 - val_loss: 0.6309\n",
            "Epoch 3/10\n",
            "1110/1110 - 52s - 47ms/step - accuracy: 0.7381 - loss: 0.6589 - val_accuracy: 0.7841 - val_loss: 0.5576\n",
            "Epoch 4/10\n",
            "1110/1110 - 52s - 47ms/step - accuracy: 0.7556 - loss: 0.6159 - val_accuracy: 0.7742 - val_loss: 0.5536\n",
            "Epoch 5/10\n",
            "1110/1110 - 52s - 47ms/step - accuracy: 0.7671 - loss: 0.5856 - val_accuracy: 0.7709 - val_loss: 0.5826\n",
            "Epoch 6/10\n",
            "1110/1110 - 52s - 47ms/step - accuracy: 0.7744 - loss: 0.5653 - val_accuracy: 0.7722 - val_loss: 0.5397\n",
            "Epoch 7/10\n",
            "1110/1110 - 52s - 47ms/step - accuracy: 0.7781 - loss: 0.5521 - val_accuracy: 0.8009 - val_loss: 0.4877\n",
            "Epoch 8/10\n",
            "1110/1110 - 52s - 47ms/step - accuracy: 0.7830 - loss: 0.5395 - val_accuracy: 0.7575 - val_loss: 0.6013\n",
            "Epoch 9/10\n",
            "1110/1110 - 52s - 47ms/step - accuracy: 0.7866 - loss: 0.5277 - val_accuracy: 0.7923 - val_loss: 0.5173\n",
            "Epoch 10/10\n",
            "1110/1110 - 52s - 47ms/step - accuracy: 0.7897 - loss: 0.5187 - val_accuracy: 0.8002 - val_loss: 0.4752\n",
            "\u001b[1m1387/1387\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step\n",
            "\n",
            "Training Baseline DNN with SGD\n",
            "Epoch 1/10\n",
            "1110/1110 - 53s - 48ms/step - accuracy: 0.5763 - loss: 1.1706 - val_accuracy: 0.6520 - val_loss: 0.9163\n",
            "Epoch 2/10\n",
            "1110/1110 - 52s - 47ms/step - accuracy: 0.6428 - loss: 0.9371 - val_accuracy: 0.7025 - val_loss: 0.8098\n",
            "Epoch 3/10\n",
            "1110/1110 - 52s - 46ms/step - accuracy: 0.6731 - loss: 0.8470 - val_accuracy: 0.7059 - val_loss: 0.7458\n",
            "Epoch 4/10\n",
            "1110/1110 - 51s - 46ms/step - accuracy: 0.6940 - loss: 0.7878 - val_accuracy: 0.7308 - val_loss: 0.7133\n",
            "Epoch 5/10\n",
            "1110/1110 - 52s - 47ms/step - accuracy: 0.7083 - loss: 0.7459 - val_accuracy: 0.7398 - val_loss: 0.6384\n",
            "Epoch 6/10\n",
            "1110/1110 - 52s - 47ms/step - accuracy: 0.7198 - loss: 0.7146 - val_accuracy: 0.7388 - val_loss: 0.6504\n",
            "Epoch 7/10\n",
            "1110/1110 - 52s - 46ms/step - accuracy: 0.7284 - loss: 0.6897 - val_accuracy: 0.7602 - val_loss: 0.5890\n",
            "Epoch 8/10\n",
            "1110/1110 - 52s - 47ms/step - accuracy: 0.7355 - loss: 0.6699 - val_accuracy: 0.7766 - val_loss: 0.5804\n",
            "Epoch 9/10\n",
            "1110/1110 - 52s - 47ms/step - accuracy: 0.7395 - loss: 0.6552 - val_accuracy: 0.7762 - val_loss: 0.5608\n",
            "Epoch 10/10\n",
            "1110/1110 - 51s - 46ms/step - accuracy: 0.7454 - loss: 0.6394 - val_accuracy: 0.7615 - val_loss: 0.5559\n",
            "\u001b[1m1387/1387\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step\n",
            "\n",
            " Baseline Supervised DNN Accuracy Comparison:\n",
            "Adam: Accuracy = 80.48%\n",
            "RMSprop: Accuracy = 80.02%\n",
            "SGD: Accuracy = 76.15%\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Assume X_train, X_val, y_train, y_val already exist\n",
        "X_lab, _, y_lab, _ = train_test_split(\n",
        "    X_train, y_train, test_size=0.8, stratify=y_train, random_state=42\n",
        ")\n",
        "\n",
        "X_lab = np.array(X_lab)\n",
        "y_lab = np.array(y_lab)\n",
        "X_test = X_val\n",
        "y_test = y_val\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "\n",
        "def build_dnn(input_dim, num_classes):\n",
        "    inputs = tf.keras.Input(shape=(input_dim,))\n",
        "    x = tf.keras.layers.Dense(512, activation='relu')(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dropout(0.4)(x)\n",
        "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return tf.keras.Model(inputs, outputs)\n",
        "\n",
        "optimizers = {\n",
        "    \"Adam\": tf.keras.optimizers.Adam(),\n",
        "    \"RMSprop\": tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "    \"SGD\": tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "}\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "batch_size = 512\n",
        "epochs = 10\n",
        "\n",
        "baseline_results = {}\n",
        "\n",
        "for name, optimizer in optimizers.items():\n",
        "    print(f\"\\nTraining Baseline DNN with {name}\")\n",
        "    model = build_dnn(X_lab.shape[1], num_classes)\n",
        "    model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(\n",
        "        X_lab, y_lab,\n",
        "        validation_data=(X_test, y_test),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    y_pred = np.argmax(model.predict(X_test, batch_size=batch_size), axis=1)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    baseline_results[name] = acc\n",
        "\n",
        "# Show summary\n",
        "print(\"\\n Baseline Supervised DNN Accuracy Comparison:\")\n",
        "for name, acc in baseline_results.items():\n",
        "    print(f\"{name}: Accuracy = {acc * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uIIL7fn2dye5",
        "outputId": "95b5ebfe-715a-4edc-93c0-1edcbb3845e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1387/1387\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step\n",
            "\n",
            "Supervised DNN Accuracy: 76.15%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.99      0.93     22187\n",
            "           1       0.53      0.56      0.55     22187\n",
            "           2       0.79      0.97      0.87     22187\n",
            "           3       0.81      0.97      0.88     22187\n",
            "           4       0.99      0.99      0.99     22187\n",
            "           5       0.88      0.88      0.88     22187\n",
            "           6       1.00      1.00      1.00     22188\n",
            "           7       0.99      0.99      0.99     22188\n",
            "           8       1.00      1.00      1.00     22187\n",
            "           9       1.00      1.00      1.00     22187\n",
            "          10       0.39      0.41      0.40     22188\n",
            "          11       0.54      0.35      0.42     22187\n",
            "          12       0.68      0.46      0.55     22187\n",
            "          13       0.99      0.99      0.99     22187\n",
            "          14       0.64      0.50      0.56     22188\n",
            "          15       0.79      0.87      0.83     22187\n",
            "          16       0.87      0.88      0.88     22187\n",
            "          17       0.47      0.61      0.53     22187\n",
            "          18       0.59      0.78      0.67     22187\n",
            "          19       1.00      1.00      1.00     22188\n",
            "          20       0.68      0.56      0.61     22188\n",
            "          21       0.75      0.01      0.02     22187\n",
            "          22       0.50      0.99      0.67     22187\n",
            "          23       1.00      1.00      1.00     22187\n",
            "          24       0.67      0.72      0.69     22187\n",
            "          25       0.40      0.12      0.19     22187\n",
            "          26       0.89      1.00      0.94     22187\n",
            "          27       0.50      0.40      0.44     22187\n",
            "          28       0.81      0.99      0.89     22188\n",
            "          29       0.96      0.97      0.96     22187\n",
            "          30       0.51      0.48      0.49     22187\n",
            "          31       0.78      0.95      0.86     22187\n",
            "\n",
            "    accuracy                           0.76    709991\n",
            "   macro avg       0.76      0.76      0.74    709991\n",
            "weighted avg       0.76      0.76      0.74    709991\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ========================== Evaluation Block  of baseline DNN training with 20% label ==========================\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Make predictions\n",
        "batch_size = 512\n",
        "y_pred_prob =  model.predict(X_test, batch_size=batch_size)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "acc = accuracy_score(y_val, y_pred)\n",
        "print(f\"\\nSupervised DNN Accuracy: {acc * 100:.2f}%\")\n",
        "\n",
        "# Handle label decoding properly\n",
        "present_labels = np.unique(y_val)\n",
        "present_class_names = [str(cls_name) for cls_name in le.inverse_transform(present_labels)]\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val, y_pred, labels=present_labels, target_names=present_class_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UodUEQgfTUGL"
      },
      "source": [
        "#Mean Teacher Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "N0m633OeypOz",
        "outputId": "6533b0c8-3ec0-444f-dbbc-fd99d7d506c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üß™ Training with Adam optimizer\n",
            "\n",
            "Epoch 1/10 [Adam]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [04:01<00:00,  4.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2/10 [Adam]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:59<00:00,  4.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3/10 [Adam]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:59<00:00,  4.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4/10 [Adam]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:59<00:00,  4.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5/10 [Adam]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [04:00<00:00,  4.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6/10 [Adam]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [04:01<00:00,  4.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7/10 [Adam]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:59<00:00,  4.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8/10 [Adam]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:58<00:00,  4.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9/10 [Adam]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:57<00:00,  4.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10/10 [Adam]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:57<00:00,  4.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1387/1387\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step\n",
            "\u001b[1m1387/1387\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step\n",
            "\n",
            "üß™ Training with RMSprop optimizer\n",
            "\n",
            "Epoch 1/10 [RMSprop]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:31<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2/10 [RMSprop]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:32<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3/10 [RMSprop]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:32<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4/10 [RMSprop]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:32<00:00,  5.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5/10 [RMSprop]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:32<00:00,  5.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6/10 [RMSprop]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:31<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7/10 [RMSprop]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:32<00:00,  5.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8/10 [RMSprop]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:31<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9/10 [RMSprop]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:30<00:00,  5.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10/10 [RMSprop]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:29<00:00,  5.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1387/1387\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step\n",
            "\u001b[1m1387/1387\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step\n",
            "\n",
            "üß™ Training with SGD optimizer\n",
            "\n",
            "Epoch 1/10 [SGD]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:16<00:00,  5.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2/10 [SGD]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:17<00:00,  5.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3/10 [SGD]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:17<00:00,  5.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4/10 [SGD]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:17<00:00,  5.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5/10 [SGD]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:16<00:00,  5.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6/10 [SGD]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:17<00:00,  5.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7/10 [SGD]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:17<00:00,  5.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8/10 [SGD]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:17<00:00,  5.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9/10 [SGD]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:16<00:00,  5.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10/10 [SGD]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1110/1110 [03:16<00:00,  5.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1387/1387\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step\n",
            "\u001b[1m1387/1387\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step\n",
            "\n",
            "üìä Optimizer Comparison Results:\n",
            "Adam: Student Acc = 80.43%, Teacher Acc = 81.02%\n",
            "RMSprop: Student Acc = 81.11%, Teacher Acc = 81.16%\n",
            "SGD: Student Acc = 78.27%, Teacher Acc = 78.24%\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import clone_model\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Assume X_train, X_val, y_train, y_val already exist\n",
        "# Split 20% labeled, 80% unlabeled from training set\n",
        "X_lab, X_unlab, y_lab, _ = train_test_split(\n",
        "    X_train, y_train, test_size=0.8, stratify=y_train, random_state=42\n",
        ")\n",
        "\n",
        "X_lab = np.array(X_lab)\n",
        "y_lab = np.array(y_lab)\n",
        "X_unlab = np.array(X_unlab)\n",
        "X_test = X_val\n",
        "y_test = y_val\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "\n",
        "def build_dnn(input_dim, num_classes):\n",
        "    inputs = tf.keras.Input(shape=(input_dim,))\n",
        "    x = tf.keras.layers.Dense(512, activation='relu')(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dropout(0.4)(x)\n",
        "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return tf.keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "optimizers = {\n",
        "    \"Adam\": tf.keras.optimizers.Adam(),\n",
        "    \"RMSprop\": tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "    \"SGD\": tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "}\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "batch_size = 512\n",
        "epochs = 10\n",
        "ema_decay = 0.99\n",
        "confidence_threshold = 0.9\n",
        "\n",
        "# === Run training for each optimizer ===\n",
        "results = {}\n",
        "\n",
        "for name, optimizer in optimizers.items():\n",
        "    print(f\"\\nüß™ Training with {name} optimizer\")\n",
        "    student = build_dnn(X_lab.shape[1], num_classes)\n",
        "    teacher = clone_model(student)\n",
        "    teacher.set_weights(student.get_weights())\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print(f\"\\nEpoch {epoch}/{epochs} [{name}]\")\n",
        "        idxs = np.arange(len(X_lab))\n",
        "        np.random.shuffle(idxs)\n",
        "\n",
        "        for i in tqdm(range(0, len(idxs), batch_size)):\n",
        "            batch_idx = idxs[i:i+batch_size]\n",
        "            x_l_batch = tf.convert_to_tensor(X_lab[batch_idx])\n",
        "            y_l_batch = tf.convert_to_tensor(y_lab[batch_idx])\n",
        "            unlab_idx = np.random.choice(len(X_unlab), size=len(batch_idx))\n",
        "            x_u_batch = tf.convert_to_tensor(X_unlab[unlab_idx])\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                y_l_pred = student(x_l_batch, training=True)\n",
        "                y_u_pred = student(x_u_batch, training=True)\n",
        "                y_u_teacher = tf.stop_gradient(teacher(x_u_batch, training=False))\n",
        "\n",
        "                mask = tf.reduce_max(y_u_teacher, axis=1) > confidence_threshold\n",
        "                masked_student = tf.boolean_mask(y_u_pred, mask)\n",
        "                masked_teacher = tf.boolean_mask(y_u_teacher, mask)\n",
        "\n",
        "                consistency_loss = tf.reduce_mean(tf.square(masked_student - masked_teacher))\n",
        "                sup_loss = loss_fn(y_l_batch, y_l_pred)\n",
        "                total_loss = sup_loss + consistency_loss\n",
        "\n",
        "            grads = tape.gradient(total_loss, student.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(grads, student.trainable_weights))\n",
        "\n",
        "            # EMA update\n",
        "            student_weights = student.get_weights()\n",
        "            teacher_weights = teacher.get_weights()\n",
        "            teacher.set_weights([\n",
        "                ema_decay * t + (1 - ema_decay) * s\n",
        "                for s, t in zip(student_weights, teacher_weights)\n",
        "            ])\n",
        "\n",
        "    # Final Evaluation\n",
        "    student_pred = np.argmax(student.predict(X_test, batch_size=batch_size), axis=1)\n",
        "    teacher_pred = np.argmax(teacher.predict(X_test, batch_size=batch_size), axis=1)\n",
        "    student_acc = accuracy_score(y_test, student_pred)\n",
        "    teacher_acc = accuracy_score(y_test, teacher_pred)\n",
        "\n",
        "    results[name] = {\n",
        "        \"Student Accuracy\": student_acc,\n",
        "        \"Teacher Accuracy\": teacher_acc\n",
        "    }\n",
        "\n",
        "# Show summary\n",
        "print(\"\\nOptimizer Comparison Results:\")\n",
        "for name, accs in results.items():\n",
        "    print(f\"{name}: Student Acc = {accs['Student Accuracy']*100:.2f}%, Teacher Acc = {accs['Teacher Accuracy']*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwHuk--LQPc5",
        "outputId": "a0f2fd74-ed92-4d21-a971-6b3fe637af6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report for SGD Optimizer\n",
            "\n",
            " Student Model Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.99      0.92     22187\n",
            "           1       0.50      0.58      0.54     22187\n",
            "           2       0.77      0.96      0.86     22187\n",
            "           3       0.81      0.96      0.88     22187\n",
            "           4       1.00      0.99      0.99     22187\n",
            "           5       0.92      0.83      0.87     22187\n",
            "           6       1.00      1.00      1.00     22188\n",
            "           7       0.98      0.99      0.99     22188\n",
            "           8       1.00      0.99      1.00     22187\n",
            "           9       1.00      1.00      1.00     22187\n",
            "          10       0.52      0.11      0.19     22188\n",
            "          11       0.41      0.75      0.53     22187\n",
            "          12       0.58      0.71      0.64     22187\n",
            "          13       0.99      0.99      0.99     22187\n",
            "          14       0.65      0.48      0.55     22188\n",
            "          15       0.79      0.86      0.82     22187\n",
            "          16       0.84      0.93      0.88     22187\n",
            "          17       0.52      0.48      0.50     22187\n",
            "          18       0.63      0.49      0.55     22187\n",
            "          19       1.00      1.00      1.00     22188\n",
            "          20       0.69      0.55      0.61     22188\n",
            "          21       0.98      0.85      0.91     22187\n",
            "          22       0.87      0.98      0.92     22187\n",
            "          23       1.00      1.00      1.00     22187\n",
            "          24       0.69      0.68      0.69     22187\n",
            "          25       0.43      0.18      0.26     22187\n",
            "          26       0.89      1.00      0.94     22187\n",
            "          27       0.49      0.37      0.42     22187\n",
            "          28       0.79      0.99      0.88     22188\n",
            "          29       0.96      0.98      0.97     22187\n",
            "          30       0.54      0.40      0.46     22187\n",
            "          31       0.72      0.96      0.83     22187\n",
            "\n",
            "    accuracy                           0.78    709991\n",
            "   macro avg       0.78      0.78      0.77    709991\n",
            "weighted avg       0.78      0.78      0.77    709991\n",
            "\n",
            "\n",
            "Teacher Model Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.99      0.93     22187\n",
            "           1       0.52      0.56      0.53     22187\n",
            "           2       0.74      0.99      0.85     22187\n",
            "           3       0.79      0.97      0.87     22187\n",
            "           4       0.99      0.99      0.99     22187\n",
            "           5       0.91      0.83      0.87     22187\n",
            "           6       1.00      1.00      1.00     22188\n",
            "           7       0.98      0.99      0.99     22188\n",
            "           8       1.00      0.99      1.00     22187\n",
            "           9       1.00      1.00      1.00     22187\n",
            "          10       0.51      0.12      0.19     22188\n",
            "          11       0.43      0.72      0.53     22187\n",
            "          12       0.70      0.42      0.53     22187\n",
            "          13       0.99      0.99      0.99     22187\n",
            "          14       0.70      0.45      0.55     22188\n",
            "          15       0.74      0.88      0.80     22187\n",
            "          16       0.84      0.92      0.88     22187\n",
            "          17       0.49      0.53      0.51     22187\n",
            "          18       0.58      0.82      0.68     22187\n",
            "          19       1.00      1.00      1.00     22188\n",
            "          20       0.70      0.53      0.60     22188\n",
            "          21       0.98      0.85      0.91     22187\n",
            "          22       0.87      0.97      0.92     22187\n",
            "          23       1.00      1.00      1.00     22187\n",
            "          24       0.70      0.68      0.69     22187\n",
            "          25       0.44      0.13      0.20     22187\n",
            "          26       0.87      1.00      0.93     22187\n",
            "          27       0.51      0.40      0.45     22187\n",
            "          28       0.72      1.00      0.84     22188\n",
            "          29       0.95      0.98      0.96     22187\n",
            "          30       0.53      0.40      0.46     22187\n",
            "          31       0.76      0.95      0.84     22187\n",
            "\n",
            "    accuracy                           0.78    709991\n",
            "   macro avg       0.77      0.78      0.76    709991\n",
            "weighted avg       0.77      0.78      0.76    709991\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "# After evaluation in each optimizer loop\n",
        "print(f\"\\nClassification Report for {name} Optimizer\")\n",
        "\n",
        "# Student\n",
        "print(f\"\\n Student Model Report:\")\n",
        "print(classification_report(\n",
        "    y_test,\n",
        "    student_pred,\n",
        "    labels=np.unique(y_test)\n",
        "))\n",
        "\n",
        "# Teacher\n",
        "print(f\"\\nTeacher Model Report:\")\n",
        "print(classification_report(\n",
        "    y_test,\n",
        "    teacher_pred,\n",
        "    labels=np.unique(y_test)\n",
        "))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PyXRtD4gdZX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names, title):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=False, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(title, fontsize=16)\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "yOTNiOQxgzol",
        "outputId": "5ba4e69b-cc37-468c-828e-9c29a10b060b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'student_pred' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-3893738814>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Student Confusion Matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{name} - Student Confusion Matrix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Teacher Confusion Matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'student_pred' is not defined"
          ]
        }
      ],
      "source": [
        "# If using LabelEncoder and want readable labels\n",
        "class_names = le.classes_.tolist() if le else [f\"Class_{i}\" for i in range(num_classes)]\n",
        "\n",
        "# Student Confusion Matrix\n",
        "plot_confusion_matrix(y_test, student_pred, class_names, title=f'{name} - Student Confusion Matrix')\n",
        "\n",
        "# Teacher Confusion Matrix\n",
        "plot_confusion_matrix(y_test, teacher_pred, class_names, title=f'{name} - Teacher Confusion Matrix')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ny0NPi0g0SO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}